{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TvkG8zWlBSNJ"
      },
      "outputs": [],
      "source": [
        "!unzip real_data.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1-GQ3xnX_RUh"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import os\n",
        "\n",
        "target_length = 250\n",
        "\n",
        "def encode_sequences(tokenizer, source_sequences, target_sequences, max_length=512):\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "    target_ids = []\n",
        "\n",
        "    for src, tgt in zip(source_sequences, target_sequences):\n",
        "        src_tokenized = tokenizer.encode_plus(src, max_length=max_length, padding='max_length', truncation=True, return_tensors=\"pt\")\n",
        "        tgt_tokenized = tokenizer.encode_plus(tgt, max_length=max_length, padding='max_length', truncation=True, return_tensors=\"pt\")\n",
        "\n",
        "        input_ids.append(src_tokenized['input_ids'])\n",
        "        attention_masks.append(src_tokenized['attention_mask'])\n",
        "        target_ids.append(tgt_tokenized['input_ids'])\n",
        "\n",
        "    return torch.cat(input_ids), torch.cat(attention_masks), torch.cat(target_ids)\n",
        "\n",
        "def load_dna_sequences(folder):\n",
        "    sequences = []\n",
        "    for filename in sorted(os.listdir(folder)):\n",
        "        if filename.endswith('.dna'):\n",
        "            with open(os.path.join(folder, filename), 'r') as file:\n",
        "                # Read the file content\n",
        "                content = file.read()\n",
        "                # Remove whitespaces, newlines, and special characters\n",
        "                cleaned_content = ''.join(filter(str.isalpha, content))\n",
        "                sequences.append(cleaned_content.upper())  # Convert to upper case if needed\n",
        "    return sequences\n",
        "\n",
        "# Load training, validation, and test sets\n",
        "train_data = load_dna_sequences('train_data')\n",
        "train_labels = load_dna_sequences('train_labels')\n",
        "val_data = load_dna_sequences('val_data')\n",
        "val_labels = load_dna_sequences('val_labels')\n",
        "test_data = load_dna_sequences('test_data')\n",
        "test_labels = load_dna_sequences('test_labels')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1E73te-oY5s",
        "outputId": "acafb265-d1fb-44f1-97cc-5add19ce98b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.99\n"
          ]
        }
      ],
      "source": [
        "%pip install sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Db8imB7nvH4"
      },
      "outputs": [],
      "source": [
        "from transformers import ByT5Tokenizer, T5ForConditionalGeneration\n",
        "\n",
        "model = T5ForConditionalGeneration.from_pretrained('google/byt5-small')\n",
        "tokenizer = ByT5Tokenizer.from_pretrained('google/byt5-small')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N1G8X22ZNf-s"
      },
      "outputs": [],
      "source": [
        "train_input_ids, train_attention_masks, train_target_ids = encode_sequences(tokenizer, train_data, train_labels, target_length)\n",
        "val_input_ids, val_attention_masks, val_target_ids = encode_sequences(tokenizer, val_data, val_labels, target_length)\n",
        "test_input_ids, test_attention_masks, test_target_ids = encode_sequences(tokenizer, test_data, test_labels, target_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eJAklJclNsZt"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "batch_size = 8  # Adjust based on your GPU capacity\n",
        "\n",
        "train_dataset = TensorDataset(train_input_ids, train_attention_masks, train_target_ids)\n",
        "val_dataset = TensorDataset(val_input_ids, val_attention_masks, val_target_ids)\n",
        "test_dataset = TensorDataset(test_input_ids, test_attention_masks, test_target_ids)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BCunF9hcPKYU",
        "outputId": "5642aa52-ad72-4c0e-f400-9245e5507bb2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 3.372872178753217\n",
            "Validation Loss: 1.887516846259435\n",
            "Validation Loss: 0.5185126985112826\n",
            "Validation Loss: 0.07291650065841775\n",
            "Validation Loss: 0.05703257790689046\n"
          ]
        }
      ],
      "source": [
        "from transformers import AdamW\n",
        "import torch\n",
        "\n",
        "# Check if CUDA is available and set it as the default device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
        "\n",
        "model.to(device)\n",
        "model.train()\n",
        "\n",
        "num_epochs = 5\n",
        "for epoch in range(num_epochs):\n",
        "    # Training loop\n",
        "    for batch in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        input_ids, attention_mask, labels = [b.to(device) for b in batch]\n",
        "\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # Validation loop\n",
        "    model.eval()\n",
        "    total_eval_loss = 0\n",
        "    for batch in val_loader:\n",
        "        input_ids, attention_mask, labels = [b.to(device) for b in batch]\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            loss = outputs.loss\n",
        "            total_eval_loss += loss.item()\n",
        "\n",
        "    avg_val_loss = total_eval_loss / len(val_loader)\n",
        "    print(f'Validation Loss: {avg_val_loss}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SnkL4QpUSsdf"
      },
      "outputs": [],
      "source": [
        "prediction_length = 96\n",
        "\n",
        "predictions = []\n",
        "actuals = []\n",
        "\n",
        "model.eval()\n",
        "\n",
        "for batch in test_loader:\n",
        "    input_ids, attention_mask, labels = [b.to(device) for b in batch]\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(input_ids=input_ids, attention_mask=attention_mask, max_length=prediction_length,  # Set your target length here\n",
        "    min_length=prediction_length)\n",
        "\n",
        "    decoded_preds = [tokenizer.decode(ids, skip_special_tokens=True) for ids in outputs]\n",
        "    decoded_labels = [tokenizer.decode(ids, skip_special_tokens=True) for ids in labels]\n",
        "\n",
        "    predictions.extend(decoded_preds)\n",
        "    actuals.extend(decoded_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H-GhJ19WfnHr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5fb04e2b-d862-4443-c889-ba63cadfe8c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: levenshtein in /usr/local/lib/python3.10/dist-packages (0.23.0)\n",
            "Requirement already satisfied: rapidfuzz<4.0.0,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from levenshtein) (3.5.2)\n"
          ]
        }
      ],
      "source": [
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
        "%pip install levenshtein"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gBpK1UH7SuNz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0746ab3-012c-4b0f-8be4-de99ec232c2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CGGGAAGCCCGCCGACAACCGACTGTGGTCTTTGATTTATACTCGGTCACATGATCAATCGCTGACTACGTTCAGATCGTACCGCA#\n",
            "TGAACGAGTTTGGGAAGCCCGCCGACAACCGACTGTGGTCTTTGATTTATACTCGGTCACATGATCAATCGCTGACTACGTTCAGATCGTACCGCA\n",
            "[0.010416666666666666, 0.5833333333333334, 0.010416666666666666, 0.052083333333333336, 0.010416666666666666, 0.05154639175257732, 0.010416666666666666, 0.020833333333333332, 0.042105263157894736, 0.031578947368421054, 0.010416666666666666, 0.03125, 0.041237113402061855, 0.23958333333333334, 0.03125, 0.1111111111111111, 0.010416666666666666, 0.020833333333333332, 0.041666666666666664, 0.03125, 0.030927835051546393, 0.03125, 0.052083333333333336, 0.03125, 0.07291666666666667, 0.03125, 0.0425531914893617, 0.010416666666666666, 0.010416666666666666, 0.05319148936170213, 0.4, 0.020833333333333332, 0.4895833333333333, 0.40217391304347827, 0.020833333333333332, 0.19791666666666666, 0.041666666666666664, 0.010416666666666666, 0.21875, 0.11458333333333333, 0.041666666666666664, 0.052083333333333336, 0.14583333333333334, 0.125, 0.03125, 0.053763440860215055, 0.041666666666666664, 0.0425531914893617, 0.21875, 0.3333333333333333, 0.10416666666666667, 0.03125, 0.010416666666666666, 0.5684210526315789, 0.23958333333333334, 0.425531914893617, 0.4895833333333333, 0.07446808510638298, 0.03125, 0.15625, 0.09375, 0.4787234042553192, 0.125, 0.03125, 0.05263157894736842, 0.32978723404255317, 0.16666666666666666, 0.010416666666666666, 0.03125, 0.14583333333333334, 0.03125, 0.5684210526315789, 0.041237113402061855, 0.020833333333333332, 0.0425531914893617, 0.041666666666666664, 0.5360824742268041, 0.030927835051546393, 0.010416666666666666, 0.125, 0.7291666666666666, 0.03125, 0.041666666666666664, 0.10416666666666667, 0.010416666666666666, 0.0625, 0.03125, 0.021052631578947368, 0.010416666666666666, 0.05154639175257732, 0.24731182795698925, 0.020833333333333332, 0.010416666666666666, 0.020833333333333332, 0.041666666666666664, 0.22916666666666666, 0.11458333333333333, 0.10638297872340426, 0.11458333333333333, 0.052083333333333336, 0.03125, 0.3617021276595745, 0.14432989690721648, 0.010416666666666666, 0.042105263157894736, 0.05154639175257732, 0.041666666666666664, 0.020833333333333332, 0.020833333333333332, 0.020833333333333332, 0.010416666666666666, 0.03125, 0.3854166666666667, 0.03125, 0.5104166666666666, 0.020833333333333332, 0.041666666666666664, 0.4479166666666667, 0.16666666666666666, 0.03125, 0.3333333333333333, 0.020833333333333332, 0.09375, 0.22916666666666666, 0.052083333333333336, 0.010416666666666666, 0.010416666666666666, 0.0425531914893617, 0.020833333333333332, 0.21875, 0.06315789473684211, 0.3333333333333333, 0.07216494845360824, 0.020833333333333332, 0.07291666666666667, 0.010416666666666666, 1.0, 0.03125, 0.042105263157894736, 0.010416666666666666, 0.03125, 0.052083333333333336, 0.010416666666666666, 0.020618556701030927, 0.09375, 0.05319148936170213, 0.15625, 0.3958333333333333, 0.11458333333333333, 0.18947368421052632, 0.03125, 0.15625, 0.28125, 0.125, 0.03125, 0.010416666666666666, 0.010416666666666666, 0.03125, 0.14583333333333334, 0.041666666666666664, 0.030927835051546393, 0.010416666666666666, 0.041666666666666664, 0.010416666666666666, 0.4583333333333333, 0.05102040816326531, 0.052083333333333336, 0.06315789473684211, 0.28125, 0.2755102040816326, 0.030927835051546393, 0.3711340206185567, 0.010416666666666666, 0.03125, 0.03125, 0.010416666666666666, 0.23958333333333334, 0.25, 0.08333333333333333, 0.041666666666666664, 0.04081632653061224, 0.42105263157894735, 0.052083333333333336, 0.010416666666666666, 0.21505376344086022, 0.14583333333333334, 0.010416666666666666, 0.53125, 0.042105263157894736, 0.052083333333333336, 0.03125, 0.020833333333333332, 0.3958333333333333, 0.010416666666666666, 0.22105263157894736, 0.010416666666666666, 0.34375, 0.11458333333333333, 0.3229166666666667, 0.13829787234042554, 0.20833333333333334, 0.031578947368421054, 0.030927835051546393, 0.4583333333333333, 0.05154639175257732, 0.2765957446808511, 0.5208333333333334, 0.03125, 0.010416666666666666, 0.010416666666666666, 0.020833333333333332, 0.041237113402061855, 0.53125, 0.34375, 0.07291666666666667, 0.19791666666666666, 0.03125, 0.11458333333333333, 0.23958333333333334, 0.06451612903225806, 0.03125, 0.0625, 0.020833333333333332, 0.3229166666666667, 0.0625, 0.010416666666666666, 0.010416666666666666, 0.4479166666666667, 0.0625, 0.052083333333333336, 0.010416666666666666, 0.5416666666666666, 0.031578947368421054, 0.03125, 0.010416666666666666, 0.23958333333333334, 0.21875, 0.010416666666666666, 0.125, 0.08333333333333333, 0.061224489795918366, 0.052083333333333336, 0.53125, 0.07291666666666667, 0.3854166666666667, 0.336734693877551, 0.010416666666666666, 0.010416666666666666, 0.5729166666666666, 0.0625, 0.010416666666666666, 0.0625, 0.2916666666666667, 0.043010752688172046, 0.0625, 0.08247422680412371, 0.010416666666666666, 0.4270833333333333, 0.031578947368421054, 0.041666666666666664, 0.030927835051546393, 0.052083333333333336, 0.08333333333333333, 0.3645833333333333, 0.041666666666666664, 0.010416666666666666, 0.08333333333333333, 0.020833333333333332, 0.010416666666666666, 0.03125, 0.07291666666666667, 0.13541666666666666, 0.0625, 0.030927835051546393, 0.11458333333333333, 0.061855670103092786, 0.052083333333333336, 0.20833333333333334, 0.3894736842105263, 0.03125, 0.03125, 0.041666666666666664, 0.052083333333333336, 0.031578947368421054, 0.041666666666666664, 0.07368421052631578, 0.10416666666666667, 0.11458333333333333, 0.10416666666666667, 0.020833333333333332, 0.1875, 0.020833333333333332, 0.041237113402061855, 0.03125, 0.3804347826086957, 0.17708333333333334, 0.425531914893617, 0.07142857142857142, 0.125, 0.125, 0.010416666666666666, 0.23958333333333334, 0.010638297872340425, 0.052083333333333336, 0.052083333333333336, 0.3157894736842105, 0.03125, 0.10416666666666667, 0.03125, 0.09375, 0.03125, 0.5, 0.05319148936170213, 0.031914893617021274, 0.03125, 0.061855670103092786, 0.05319148936170213, 0.03125, 0.21875, 0.125, 0.0625, 0.020833333333333332, 0.010416666666666666, 0.061855670103092786, 0.03125, 0.08421052631578947, 0.010416666666666666, 0.03125, 0.041666666666666664, 0.19791666666666666, 0.052083333333333336, 0.08333333333333333, 0.020833333333333332, 0.10309278350515463, 0.010416666666666666, 0.15625, 0.23958333333333334, 0.03125, 0.03125, 0.07526881720430108, 0.052083333333333336, 0.052083333333333336, 0.03125, 0.06451612903225806, 0.010416666666666666, 0.03125, 0.07291666666666667, 0.17894736842105263, 0.3020833333333333, 0.4895833333333333, 0.20618556701030927, 0.08333333333333333, 0.3020833333333333, 0.021052631578947368, 0.08421052631578947, 0.19791666666666666, 0.28125, 0.03125, 0.041666666666666664, 0.0625, 0.06521739130434782, 0.5104166666666666, 0.03125, 0.03125, 0.03125, 0.05263157894736842, 0.010416666666666666, 0.041666666666666664, 0.03125, 0.0625, 0.3854166666666667, 0.5520833333333334, 0.15625, 0.5208333333333334, 0.03125, 0.14583333333333334, 0.25, 0.052083333333333336, 0.3645833333333333]\n",
            "95\n",
            "96\n",
            "Median Levenshtein Distance: 0.052083333333333336\n",
            "Max Levenshtein Distance: 1.0\n",
            "Min Levenshtein Distance: 0.010416666666666666\n",
            "Average Levenshtein Distance: 0.12331094407107385\n",
            "379\n"
          ]
        }
      ],
      "source": [
        "from Levenshtein import distance as levenshtein_distance\n",
        "import numpy as np\n",
        "\n",
        "# Store individual distances\n",
        "distances = []\n",
        "for pred, actual in zip(predictions, actuals):\n",
        "    if len(actual) > 0:  # To avoid division by zero\n",
        "        distances.append(levenshtein_distance(pred, actual) / len(actual))\n",
        "\n",
        "print(predictions[39])\n",
        "print(actuals[39])\n",
        "\n",
        "print(distances)\n",
        "print(len(predictions[41]))\n",
        "print(len(actuals[41]))\n",
        "# Calculate the median distance\n",
        "max_distance = max(distances)\n",
        "min_distance = min(distances)\n",
        "median_distance = np.median(distances)\n",
        "average_distance = np.average(distances)\n",
        "print(f\"Median Levenshtein Distance: {median_distance}\")\n",
        "print(f\"Max Levenshtein Distance: {max_distance}\")\n",
        "print(f\"Min Levenshtein Distance: {min_distance}\")\n",
        "print(f\"Average Levenshtein Distance: {average_distance}\")\n",
        "\n",
        "print(len(distances))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c9GUVXPyQQ9-"
      },
      "outputs": [],
      "source": [
        "# Save the model\n",
        "model.save_pretrained('dna_t5_model')\n",
        "\n",
        "# Load the model\n",
        "model = T5ForConditionalGeneration.from_pretrained('dna_t5_model')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}