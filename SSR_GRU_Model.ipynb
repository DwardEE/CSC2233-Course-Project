{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PtiaUAq2--jv"
      },
      "outputs": [],
      "source": [
        "!unzip real_data.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "\n",
        "def load_dna_sequences(folder):\n",
        "    sequences = []\n",
        "    for filename in sorted(os.listdir(folder)):\n",
        "        if filename.endswith('.dna'):\n",
        "            with open(os.path.join(folder, filename), 'r') as file:\n",
        "                # Read the file content\n",
        "                content = file.read()\n",
        "                # Remove whitespaces, newlines, and special characters\n",
        "                cleaned_content = ''.join(filter(str.isalpha, content))\n",
        "                sequences.append(cleaned_content.upper())  # Convert to upper case if needed\n",
        "    return sequences\n",
        "\n",
        "# Load training, validation, and test sets\n",
        "train_data = load_dna_sequences('train_data')\n",
        "train_labels = load_dna_sequences('train_labels')\n",
        "val_data = load_dna_sequences('val_data')\n",
        "val_labels = load_dna_sequences('val_labels')\n",
        "test_data = load_dna_sequences('test_data')\n",
        "test_labels = load_dna_sequences('test_labels')"
      ],
      "metadata": {
        "id": "1HZOPTeaj7Zq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Custom Dataset Class\n",
        "class DNASequenceDataset(Dataset):\n",
        "    def __init__(self, sequences, labels, max_seq_len):\n",
        "        self.sequences = sequences\n",
        "        self.labels = labels\n",
        "        self.max_seq_len = max_seq_len\n",
        "        self.label_encoder = LabelEncoder()\n",
        "        self.label_encoder.fit(['A', 'C', 'G', 'T', 'N'])  # N for padding\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sequences)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sequence = self.sequences[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        # Encode sequence and label\n",
        "        encoded_seq = self.label_encoder.transform(list(sequence + 'N' * (self.max_seq_len - len(sequence))))\n",
        "        encoded_label = self.label_encoder.transform(list(label + 'N' * (self.max_seq_len - len(label))))\n",
        "\n",
        "        return torch.tensor(encoded_seq, dtype=torch.long), torch.tensor(encoded_label, dtype=torch.long)\n",
        "\n",
        "# Determine the maximum sequence length for padding\n",
        "max_seq_len = max(max(len(seq) for seq in train_data), max(len(seq) for seq in train_labels))\n",
        "\n",
        "# Create datasets\n",
        "train_dataset = DNASequenceDataset(train_data, train_labels, max_seq_len)\n",
        "val_dataset = DNASequenceDataset(val_data, val_labels, max_seq_len)\n",
        "test_dataset = DNASequenceDataset(test_data, test_labels, max_seq_len)\n",
        "\n",
        "# Create dataloaders\n",
        "batch_size = 32  # You can adjust this based on your GPU capacity\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "zylfbY7MuBSU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class DNAGRU(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers, bidirectional=False, dropout=0.5):\n",
        "        super(DNAGRU, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_layers = num_layers\n",
        "        self.bidirectional = bidirectional\n",
        "\n",
        "        # GRU Layer\n",
        "        self.gru = nn.GRU(input_dim, hidden_dim, num_layers, batch_first=True, bidirectional=bidirectional, dropout=dropout if num_layers > 1 else 0)\n",
        "\n",
        "        # Linear layer that maps from hidden state space to tag space\n",
        "        # Adjust output dimension if bidirectional\n",
        "        gru_output_dim = hidden_dim * 2 if bidirectional else hidden_dim\n",
        "        self.hidden2tag = nn.Linear(gru_output_dim, output_dim)\n",
        "\n",
        "    def forward(self, sequence):\n",
        "        gru_out, _ = self.gru(sequence)\n",
        "        tag_space = self.hidden2tag(gru_out)\n",
        "        tag_scores = torch.log_softmax(tag_space, dim=2)\n",
        "        return tag_scores\n",
        "\n",
        "# Parameters for the model\n",
        "input_dim = 5  # 4 nucleotides + 1 for padding\n",
        "hidden_dim = 64  # Can be adjusted\n",
        "output_dim = 5  # 4 nucleotides + 1 for padding\n",
        "num_layers = 2  # Adjusted\n",
        "bidirectional = True  # Using bidirectional GRU\n",
        "\n",
        "model = DNAGRU(input_dim, hidden_dim, output_dim, num_layers, bidirectional)\n"
      ],
      "metadata": {
        "id": "P6qPJJG5l22e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# Check if CUDA is available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Move the model to the specified device\n",
        "model.to(device)\n",
        "\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.NLLLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "\n",
        "# Function to convert sequences to one-hot encodings\n",
        "def sequence_to_one_hot(sequence, sequence_length):\n",
        "    one_hot = torch.zeros(sequence_length, 5)  # 5 for A, C, G, T, N\n",
        "    one_hot[torch.arange(sequence_length), sequence] = 1\n",
        "    return one_hot\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 20  # Can be adjusted\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    for sequences, labels in train_loader:\n",
        "        # Convert sequences to one hot encoding and move to GPU\n",
        "        sequences_one_hot = torch.stack([sequence_to_one_hot(seq, max_seq_len) for seq in sequences]).to(device)\n",
        "\n",
        "        # Move labels to the same device as model\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward\n",
        "        outputs = model(sequences_one_hot)\n",
        "\n",
        "        # Compute loss; assuming labels are class indices, not one-hot encoded\n",
        "        loss = criterion(outputs.view(-1, 5), labels.view(-1))\n",
        "\n",
        "        # Backward + optimize\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Loss: {running_loss / len(train_loader)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rO-L_-4GuGrU",
        "outputId": "6234f4b0-789a-4815-d21b-6389058341a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 1.5587398906548817\n",
            "Epoch 2, Loss: 1.4822580615679424\n",
            "Epoch 3, Loss: 1.4207678768369887\n",
            "Epoch 4, Loss: 1.3705560465653737\n",
            "Epoch 5, Loss: 1.312188294198778\n",
            "Epoch 6, Loss: 1.234842558701833\n",
            "Epoch 7, Loss: 1.1314069694942899\n",
            "Epoch 8, Loss: 1.006300785475307\n",
            "Epoch 9, Loss: 0.8789858867724737\n",
            "Epoch 10, Loss: 0.76055322918627\n",
            "Epoch 11, Loss: 0.666410830285814\n",
            "Epoch 12, Loss: 0.6033182698819373\n",
            "Epoch 13, Loss: 0.5671272021200922\n",
            "Epoch 14, Loss: 0.5373486007253329\n",
            "Epoch 15, Loss: 0.5244159491525756\n",
            "Epoch 16, Loss: 0.5212437137961388\n",
            "Epoch 17, Loss: 0.5133695751428604\n",
            "Epoch 18, Loss: 0.5114726995428404\n",
            "Epoch 19, Loss: 0.502085294160578\n",
            "Epoch 20, Loss: 0.4976774487230513\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_sequence(output, label_encoder):\n",
        "    # Convert output to predicted class indices\n",
        "    _, predicted_indices = torch.max(output, 2)\n",
        "\n",
        "    # Ensure the tensor is on the CPU before converting to numpy\n",
        "    predicted_indices = predicted_indices.cpu()\n",
        "\n",
        "    # Convert indices to nucleotides\n",
        "    predicted_sequences = [\"\".join(label_encoder.inverse_transform(indices.numpy())) for indices in predicted_indices]\n",
        "    return predicted_sequences\n",
        "\n",
        "def predict(model, data_loader, label_encoder):\n",
        "    model.eval()\n",
        "    all_predictions = []\n",
        "    with torch.no_grad():\n",
        "        for sequences, _ in data_loader:\n",
        "            sequences_one_hot = torch.stack([sequence_to_one_hot(seq, max_seq_len) for seq in sequences]).to(device)\n",
        "            outputs = model(sequences_one_hot)\n",
        "            predictions = decode_sequence(outputs, label_encoder)\n",
        "            all_predictions.extend(predictions)\n",
        "\n",
        "    return all_predictions"
      ],
      "metadata": {
        "id": "FhTMhjSqvZKl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import editdistance\n",
        "\n",
        "def calculate_normalized_edit_distance(predictions, true_labels):\n",
        "    total_distance = 0\n",
        "    total_length = 0\n",
        "\n",
        "    for pred, true in zip(predictions, true_labels):\n",
        "        # Compute the edit distance for each pair of sequences\n",
        "        distance = editdistance.eval(pred, true)\n",
        "        total_distance += distance\n",
        "        total_length += len(true)\n",
        "\n",
        "    # Normalizing the total edit distance by the total length of all sequences\n",
        "    avg_normalized_distance = total_distance / total_length\n",
        "    return avg_normalized_distance"
      ],
      "metadata": {
        "id": "F3RsJERNvdm_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generating predictions on the test set\n",
        "test_predictions = predict(model, test_loader, train_dataset.label_encoder)\n",
        "\n",
        "# Truncate the predictions and true labels to their original lengths (remove padding)\n",
        "truncated_predictions = [pred[:len(true)] for pred, true in zip(test_predictions, test_labels)]\n",
        "truncated_test_labels = [true.rstrip('N') for true in test_labels]  # Assuming 'N' is used for padding\n",
        "\n",
        "print(len(truncated_predictions))\n",
        "\n",
        "# Calculate the average normalized edit distance\n",
        "avg_normalized_edit_distance = calculate_normalized_edit_distance(truncated_predictions, truncated_test_labels)\n",
        "print(f\"Average Normalized Edit Distance on Test Set: {avg_normalized_edit_distance}\")"
      ],
      "metadata": {
        "id": "qNaq-VKVHcDT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calculate_normalized_edit_distance(train_data, train_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1YbN-EFE4UBY",
        "outputId": "2f8ae7ca-c14b-44ae-a731-d4c697b17c0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.021975599000440982"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    }
  ]
}